dy<-predict(fitno,out2)-predict(fit,out2)
sum((dy[,1])^2)/(2*sigma^2)
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
library(datasets)
data(mtcars)
head(mtcars)
fitq1<-lm(mpg~wt+cyl,mtcars)
summary(fit)
sapply(mtcars,class)
fitq1<-lm(mpg~wt+factor(cyl),mtcars)
summary(fitq1)
fitq2<-lm(mpg~factor(cyl),mtcars)
summary(fitq2)$coef
fitq3<-lm(mpg~wt+factor(cyl)+wt*factor(cyl))
summary(fitq3)$coef
fitq3<-lm(mpg~wt+factor(cyl)+wt*factor(cyl),mtcars)
summary(fitq3)$coef
summary(fitq3)
summary(fitq1)
fitq3b<-lm(mpg~wt*factor(cyl),mtcars)
summary(fitq3b)
summary(fitq3b)$coef
compare<-anova(fitq1,fitq3)
compare$Pr
compare
fitq4<-lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fitq4)$coef
fit<-lm(mpg ~ I(wt * 0.5), data = mtcars)
summary(fit)$coef
?hatvalues
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fitq5<-lm(y~x)
hatvalues(fitq5)
dfbeta(fitq5)
influence.measures(fitq5)
summary(fitq5)
library(MASS)
?shuttle
shuttle$use.binary <- as.integer(shuttle$use == "auto")
fit <- glm(use.binary ~ wind - 1, data = shuttle, family = binomial)
summary(fit)$coef
unname(exp(coef(fit))[1]/exp(coef(fit))[2])
fit <- glm(use.binary ~ wind + magn - 1, data = shuttle, family = binomial)
exp(coef(fit))
unname(exp(coef(fit))[1]/exp(coef(fit))[2])
fit1 <- glm(use.binary ~ wind + magn - 1, data = shuttle, family = binomial)
fit2 <- glm(1 - use.binary ~ wind + magn - 1, data = shuttle, family = binomial)
coef(fit1)
coef(fit2)
fit <- glm(count ~ spray - 1, data = InsectSprays, family = poisson)
coef.exp <- exp(coef(fit))
unname(coef.exp[1] / coef.exp[2])
x <- seq(1, 1000, by = 1)
t <- log(x)
t2 <- log(10) + t
y <- ppois(x, 2)
fit1 <- glm(y ~ x + offset(t), family = poisson, data = InsectSprays)
fit2 <- glm(y ~ x + offset(t2), family = poisson, data = InsectSprays)
summary(fit1)$coef
summary(fit2)$coef
?createDatapartition
?createDataPartition
install.packages("caret")
library(carer)
library(caret)
?createDataPartition
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.package("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
rm=list(ls=())
rm(list=ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(concrete$CompressiveStrength,pch19)
plot(concrete$CompressiveStrength,pch=19)
qplot(concrete$CompressiveStrength,colour=cement,data=training)
qplot(concrete$CompressiveStrength,colour=Cement,data=training)
library(Hmisc)
training2<-sapply(training[,-CompressiveStrenght],cut2(var,g=4))
training2<-sapply(training,cut2(var,g=4))
training2<-sapply(training,cut2(,g=4))
training2<-sapply(training,cut2(var
,g=4))
x<-c(1:5,1)
library(Hmisc)
covars<-c(1:8)
concrete[,covars]<-lapply(concrete[,covars],function(x) cut2 (x,g=4))
plot(concrete$CompressiveStrength,pch=19)
qplot(concrete$CompressiveStrength,data=training)
list2env(g, .GlobalEnv)
g<-qplot(concrete$CompressiveStrength,data=training)
g
qplot(concrete,data=training)
ggplot(training, aes(concrete,))
ggplot(training, aes(concrete,dim))
ggplot(training, aes(concrete,training(1,))
ggplot(training, aes(concrete,training(1,))
ggplot(training, aes(concrete,training(1,)))
covars<-c(1:8)
concrete[,covars]<-lapply(concrete[,covars],function(x) cut2 (x,g=4))
training[,covars]<-lapply(training[,covars],function(x) cut2 (x,g=4))
qplot(concrete,data=training)
qplot(CompressiveStrength, data=training)
ggplot(training, aes(CompresiveStrength,))
ggplot(training, aes(CompressiveStrength,))
ggplot(training, aes(,CompressiveStrength))
ggplot(training, aes(,CompressiveStrength, colour=water))
ggplot(training, aes(,CompressiveStrength, colour=Water))
ggplot(training, aes(,CompressiveStrength, colour=Water))+ geom_point(alpha = 1/3)
ggplot(training, aes(,CompressiveStrength, colour=Water))+geom_point(color = "steelblue", size = 4, alpha = 1/2)
ggplot(training, aes(index,CompressiveStrength, colour=Water))
ggplot(training, aes(x=index,y=CompressiveStrength, colour=Water))
training$index <- seq(1, nrow(training))
ggplot(training, aes(x=index,y=CompressiveStrength, colour=Water))
qplot(CompressiveStrength, index ,data=training)
qplot(index, CompressiveStrength,data=training)
qplot(index, CompressiveStrength,colour=Water, data=training)
ggplot(training, aes (index, CompressiveStrength,colour=Water))
library(Hmisc)
library(caret)
library(AppliedPredictiveModeling)
ggplot(training, aes (index, CompressiveStrength,colour=Water))
ggplot(training, aes (index, CompressiveStrength,colour=Water))+geom_point(shape=1)
ggplot(training, aes (index, CompressiveStrength,colour=Water))+geom_point(shape=20)
ggplot(training, aes (index, CompressiveStrength,colour=Water))+geom_point(shape=22)
ggplot(training, aes (index, CompressiveStrength,colour=Water))+geom_point(shape=16)
ggplot(training, aes (index, CompressiveStrength,colour=Water))+geom_point(shape=16,size=3)
g <- lapply(covars, function(var) {
ggplot(training, aes (index, CompressiveStrength,colour=var))+geom_point(shape=16,size=3)
})
names(g) <- paste0("g", seq(g))
list2env(g, .GlobalEnv)
g
g1
g2
g3
g4
g5
g6
rm=g
g <- lapply(covars, function(var) {
ggplot(training, aes (x="index", y="CompressiveStrength",colour=var))+geom_point(shape=16,size=3)
})
g
g1
g <- lapply(covars, function(var) {
ggplot(training, aes (x="index", y="CompressiveStrength",colour=var))+geom_point(shape=16,size=3)
})
names(g) <- paste0("g", seq(g))
list2env(g, .GlobalEnv)
g
g1
rm=list(g,g1,g2,g3,g4,g5,g6,g7,g8)
ls=list(g,g1,g2,g3,g4,g5,g6,g7,g8)
rm(list=g,g1,g2,g3,g4,g5,g6,g7,g8)
rm(list=(g,g1,g2,g3,g4,g5,g6,g7,g8))
rm(g)
rm(g,g1,g2,g3,g4,g5,g6,g7,g8)
rm(ls,rm)
g<-ggplot(training, aes (index,CompressiveStrength,colour=Cement))+geom_point(shape=16,size=3)
g1<-ggplot(training, aes (index,CompressiveStrength,colour=BlastFurnaceSlag))+geom_point(shape=16,size=3)
g2<-ggplot(training, aes (index,CompressiveStrength,colour=FlyAsh))+geom_point(shape=16,size=3)
g3<-ggplot(training, aes (index,CompressiveStrength,colour=Water))+geom_point(shape=16,size=3)
g4<-ggplot(training, aes (index,CompressiveStrength,colour=Superplasticizer))+geom_point(shape=16,size=3)
g5<-ggplot(training, aes (index,CompressiveStrength,colour=CoarseAggregate))+geom_point(shape=16,size=3)
g6<-ggplot(training, aes (index,CompressiveStrength,colour=FineAggregate))+geom_point(shape=16,size=3)
g7<-ggplot(training, aes (index,CompressiveStrength,colour=Age))+geom_point(shape=16,size=3)
g
g1
g2
pdf(file="quizz2question2.pdf")
g
g1
g2
g3
g4
g5
g6
g7
dev.off()
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
multiplot(g,g1,g2,g3,g4,g5,g6,g7,cols=4)
multiplot(g,g1,g2,g3,g4,g5,g6,g7,cols=2)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
rm(g,g1,g2,g3,g4,g5,g6,g7)
ggplot(training, aes(SuperPlasticizer)) +
geom_histogram(binwidth = 0.01)
ggplot(training, aes(Superplasticizer)) +
geom_histogram(binwidth = 0.01)
ggplot(training, aes(Superplasticizer)) +
geom_freqpoly(binwidth = 500)
ggplot(training, aes(Superplasticizer)) +
geom_freqpoly(binwidth = 0.01)
hist(training$Superplasticizer,main="")
geom_histogram()
ggplot(training, aes(Superplasticizer)) +
geom_histogram()
hist(training$Superplasticizer,main="")
ggplot(training, aes(log(Superplasticizer)+1) +
geom_histogram()
ggplot(training, aes(log(Superplasticizer)+1) +
geom_histogram())
ggplot(training, aes(log(Superplasticizer)+1) )+
geom_histogram()
str(training)
which(training$Superplasticizer<0)
which(training$Superplasticizer>0)
which(training$Superplasticizer=0)
which(training$Superplasticizer->0)
which(training$Superplasticizer==0)
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep(^IL,training$names)
grep(^IL,names(training))
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_str], "diagnosis")]
IL_str <- grep("^IL", colnames(training), value = TRUE)
new_testing <- testing[, c(names(testing)[IL_str], "diagnosis")]
new_training<-testing[, c(names(training)[IL_str], "diagnosis")]
library(dplyr)
new_testing <- testing[, c(names(testing)[IL_str], "diagnosis")]
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
new_training<-training[, c(names(training)[IL_col_idx], "diagnosis")]
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
library(caret)
install.packages('e1071', dependencies=TRUE)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
names(new_testing)
non_pca_result
# perform PCA extraction on the new training and testing sets
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
rm(ls=list())
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain = createDataPartition(SegmentationOriginal$Case, p = 3/4)
training = segmentationOriginal[ inTrain,]
testing = segmentationOriginal[-inTrain,]
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)
training = segmentationOriginal[ inTrain,]
training = segmentationOriginal[inTrain,]
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[inTrain,]
testing = segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=segmentationOriginal)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
rm(list=ls())
set.seed(125)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[inTrain,]
testing = segmentationOriginal[-inTrain,]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[inTrain,]
testing = segmentationOriginal[-inTrain,]
modFit <- train(Case ~ .,method="rpart",data=segmentationOriginal)
library(rattle)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
rm(list=ls())
data(segmentationOriginal)
training = segmentationOriginal[Case==Train,]
training<-filter(segmentationOriginal,Case=="Train")
training<-subset(segmentationOriginal, Case=="Train")
testing<-subset(segmentationOriginal, Case=="Test")
modFit <- train(Class ~ .,method="rpart",data=training)
print(modFit$finalModel)
library(rattle)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
dim(olive)
summary(olive)
modFit <- train(Area ~ .,method="rpart",data=olive)
library(caret)
modFit <- train(Area ~ .,method="rpart",data=olive)
?tree
??tree
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=testing)
predict(modFit,newdata=newdata)
??tree
tr<-tree(Area ~ .,data=olive)
install.packages("tree")
library(tree)
tr<-tree(Area ~ .,data=olive)
predict(tr, newdata=newdata)
predict(modFit,newdata=newdata)
(
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
modFit <- train(Area ~ .,method="rpart",data=olive)
predict(modFit,newdata=newdata)
tr<-tree(Area ~ .,data=olive)
predict(tr, newdata=newdata)
rm(list=ls())
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
data(SAheart)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?SAheatr
?SAheart
logrm<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm", family="binomial")
set.seed(13234)
logrm<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm", family="binomial", data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA,logrm)
trainpred<-predit(logrm,newdata=trainSA)
trainpred<-predict(logrm,newdata=trainSA)
testpred<- predict(logrm,newdatra=testSA)
missClass(chd$trainSA,trainpred)
missClass(trainSA$chd,trainpred)
missClassTest<-missClass(testSA$chd,testpred)
missClassTrain<-missClass(trainSA$chd,trainpred)
misclassmat<-cbind(missClassTrain,missClasTest)
misclassmat<-cbind(missClassTrain,missClassTest)
Names(misclassmat)<-c("train","test")
names(misclassmat)<-c("train","test")
misclassmat
missClass(trainSA$chd, predict(logrm, trainSA))
testpred<- predict(logrm,newdata=testSA)
missClassTest<-missClass(testSA$chd,testpred)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
dim(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
ranfor<-train(y~.,method="rf",data=vowel.train)
ranfor$varImp
varranfor<-varImp(ranfor, scale = FALSE)
Varranfor
varranfor
varImp(ranfor)
ranfortest<-train(y~.,method="rf",data=vowel.test)
varranfort<-varImp(ranfortest, scale = FALSE)
varranfort
total<-rbind(vowel.train, vowel.test)
set.seed(33833)
ranfortotal<-train(y~.,method="rf",data=total)
varranfortotal<-varImp(ranfortotal, scale = FALSE)
varranfortotal
varranfor
setwd("D:/Datos Miguel Rayon/Casa/Documents/Curso Data Science J Hopkins/Machine Learning/project/Coursera_ML_Project")
trainset<-read.csv("pml-training.csv",header=T)
head(trainset)
dim(trainset)
summary(trainset)
summary(trainset$classe)
